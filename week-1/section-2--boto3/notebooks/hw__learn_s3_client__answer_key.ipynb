{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3 Operations using Boto3\n",
    "\n",
    "In this notebook, we will perform several operations on AWS S3 using Boto3. \n",
    "\n",
    "These operations include:\n",
    "\n",
    "- creating an S3 bucket\n",
    "- writing an object\n",
    "- listing objects\n",
    "- reading the contents of an object\n",
    "- deleting an object\n",
    "- updating an object\n",
    "- and handling errors for non-existent objects. \n",
    "  \n",
    "We will also demonstrate how to write files with different prefixes and query files by prefix.\n",
    "\n",
    "## For this notebook to run...\n",
    "\n",
    "You will need to have these libraries installed\n",
    "\n",
    "- `boto3`\n",
    "- `boto3-stubs[s3]`\n",
    "- `rich`\n",
    "- `ipykernel`\n",
    "\n",
    "The recommended approach is to set up your `pyproject.toml` like so:\n",
    "\n",
    "```toml\n",
    "[project]\n",
    "...\n",
    "dependencies = ['importlib-metadata; python_version<\"3.8\"', \"boto3\"]\n",
    "\n",
    "[project.optional-dependencies]\n",
    "stubs = [\"boto3-stubs[s3]\"]\n",
    "notebooks = [\"jupyterlab\", \"ipykernel\", \"rich\"]\n",
    "...\n",
    "dev = [\"cloud-course-project[test,release,static-code-qa,stubs,notebooks]\"]\n",
    "```\n",
    "\n",
    "So that `pip install --editable './[dev]'` will install all the necessary dependencies into your venv.\n",
    "\n",
    "## Instructions for setting up autocompletion in Jupyter Notebooks in VS Code\n",
    "\n",
    "1. Install the development dependencies:\n",
    "```sh\n",
    "pip install --editable './[dev]'\n",
    "```\n",
    "2. Select the notebook kernel and point it to your virtual environment:\n",
    "```sh\n",
    "which python\n",
    "```\n",
    "3. Select the VS Code Python interpreter and point it to your virtual environment:\n",
    "```sh\n",
    "which python\n",
    "```\n",
    "4. Reload the VS Code window (`Ctrl/Cmd + Shift + P` > `Developer: Reload Window`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from uuid import uuid4  # randomly generated string\n",
    "from rich import print  # pretty printing\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    from mypy_boto3_s3 import S3Client\n",
    "except ImportError:\n",
    "    print(\"mypy_boto3_s3 not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "\n",
    "# Set the profile and region for the AWS SDK (boto3) to use\n",
    "os.environ[\"AWS_PROFILE\"] = \"cloud-course\"\n",
    "os.environ[\"AWS_REGION\"] = \"us-west-2\"\n",
    "\n",
    "# Create a session using the specified profile and region\n",
    "s3_client: \"S3Client\" = boto3.client(\"s3\")\n",
    "\n",
    "BUCKET_NAME = f\"cloud-course-bucket-{str(uuid4())[:4]}\"\n",
    "\n",
    "# Single example object\n",
    "EXAMPLE_OBJECT_KEY = \"example/object/file.txt\"\n",
    "EXAMPLE_OBJECT_CONTENT = \"This is a test object.\"\n",
    "\n",
    "# Multiple example objects\n",
    "EXAMPLE_OBJECTS = [\n",
    "    (\"example-a/object/file1.txt\", \"This is a test object.\"),\n",
    "    (\"example-a/object/file2.txt\", \"This is another test object.\"),\n",
    "    (\"example-a/object/file3.txt\", \"This is yet another test object.\"),\n",
    "    (\"example-b/object/file1.txt\", \"This is a test object.\"),\n",
    "    (\"example-b/object/file2.txt\", \"This is another test object.\"),\n",
    "    (\"example-b/object/file3.txt\", \"This is yet another test object.\"),\n",
    "]\n",
    "\n",
    "print(f\"{BUCKET_NAME=}\")\n",
    "print(f\"{EXAMPLE_OBJECT_KEY=}\")\n",
    "print(f\"{EXAMPLE_OBJECT_CONTENT=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bucket\n",
    "\n",
    "In this exercise, you will create an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mypy_boto3_s3.type_defs import CreateBucketOutputTypeDef\n",
    "except ImportError:\n",
    "    print(\"boto3-stubs[s3] not installed\")\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name: str) -> Optional[\"CreateBucketOutputTypeDef\"]:\n",
    "    \"\"\"\n",
    "    Create an S3 bucket.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to create\n",
    "    :type bucket_name: str\n",
    "    \"\"\"\n",
    "    response = s3_client.create_bucket(Bucket=bucket_name)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Create the bucket\n",
    "response = create_bucket(bucket_name=BUCKET_NAME)\n",
    "print(f\"Bucket '{BUCKET_NAME}' created successfully.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write an object to the bucket\n",
    "\n",
    "In this exercise, you will write an object to the S3 bucket.\n",
    "\n",
    "\"S3 Paths\" are URLs of the form `s3://bucket-name/key`. The `key` is the path to the object in the bucket. For example, `s3://my-bucket-name/my-key` refers to the object with key `my-key` in the bucket `my-bucket-name`.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "| Path | Bucket | Object Key |\n",
    "| --- | --- | --- |\n",
    "| `s3://my-bucket/images/profile.jpeg` | `my-bucket` | `images/profile.jpeg` |\n",
    "| `s3://my-bucket/data/2021/01/01/data.csv` | `my-bucket` | `data/2021/01/01/data.csv` |\n",
    "| `s3://my-bucket/file.json` | `my-bucket` | `file.json` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mypy_boto3_s3.type_defs import PutObjectOutputTypeDef\n",
    "except ImportError:\n",
    "    print(\"boto3-stubs[s3] not installed\")\n",
    "\n",
    "\n",
    "def write_text_object_to_s3(\n",
    "    bucket_name: str,\n",
    "    object_key: str,\n",
    "    object_content: str,\n",
    ") -> Optional[\"PutObjectOutputTypeDef\"]:\n",
    "    \"\"\"\n",
    "    Write an object to an S3 bucket.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to write to\n",
    "    :param object_key: Key of the object to write\n",
    "    :param object_content: Content of the object to write\n",
    "    :return: Response from the put_object call\n",
    "    \"\"\"\n",
    "    response = s3_client.put_object(Bucket=bucket_name, Key=object_key, Body=object_content)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Write the single example to S3\n",
    "response = write_text_object_to_s3(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    object_key=EXAMPLE_OBJECT_KEY,\n",
    "    object_content=EXAMPLE_OBJECT_CONTENT,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Write the rest of the examples to S3\n",
    "for object_key, object_content in EXAMPLE_OBJECTS:\n",
    "    print(f\"Writing object to path 's3://{BUCKET_NAME}/{object_key}'\")\n",
    "    write_text_object_to_s3(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        object_key=object_key,\n",
    "        object_content=object_content,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the content of an object\n",
    "\n",
    "In this exercise, you will read the content of an object from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.response import StreamingBody\n",
    "\n",
    "\n",
    "def read_text_object_from_s3(bucket_name: str, object_key: str, verbose: bool = False) -> str | None:\n",
    "    \"\"\"\n",
    "    Read the content of an object from an S3 bucket.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to read from\n",
    "    :param object_key: Key of the object to read\n",
    "    :return: Content of the object\n",
    "    \"\"\"\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "    # Note, we need to read the bytestream from the blob and choose how we wish\n",
    "    # to interpret the bytes. In this case, we interpret them as utf-8 encoded text.\n",
    "    content_streaming_body: StreamingBody = response[\"Body\"]\n",
    "    content: str = content_streaming_body.read().decode(\"utf-8\")\n",
    "    return content\n",
    "\n",
    "\n",
    "# Read the content of the example object\n",
    "content = read_text_object_from_s3(BUCKET_NAME, EXAMPLE_OBJECT_KEY)\n",
    "if content:\n",
    "    print(f\"Content of object '{EXAMPLE_OBJECT_KEY}':\\n'{content}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1 - List objects in the bucket\n",
    "\n",
    "What if there were more than 1,000 objects in the bucket? How would you list all of them?\n",
    "\n",
    "Hints\n",
    "- Look into [\"boto3 paginators\"](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/paginators.html#creating-paginators)\n",
    "- OR Look into the [boto3 \"resource API\"](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/resources.html#resources), a powerful, but potentially less performant, object-oriented way\n",
    "  of interacting with AWS resources via boto3\n",
    "- OR consider using \"Continuation Tokens\" with the `list_objects_v2` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mypy_boto3_s3.type_defs import ListObjectsV2OutputTypeDef\n",
    "except ImportError:\n",
    "    print(\"boto3-stubs[s3] not installed\")\n",
    "\n",
    "\n",
    "def list_all_object_keys_in_bucket(bucket_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    List all objects in an S3 bucket.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to list objects from\n",
    "    :return: List of object keys\n",
    "    \"\"\"\n",
    "    objects = []\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        response: \"ListObjectsV2OutputTypeDef\" = (\n",
    "            s3_client.list_objects_v2(Bucket=bucket_name, ContinuationToken=continuation_token)\n",
    "            if continuation_token\n",
    "            else s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        )\n",
    "        objects.extend([obj[\"Key\"] for obj in response.get(\"Contents\", [])])\n",
    "        continuation_token = response.get(\"NextContinuationToken\")\n",
    "        if not continuation_token:\n",
    "            break\n",
    "    return objects\n",
    "\n",
    "\n",
    "# List all objects in the bucket\n",
    "objects = list_all_object_keys_in_bucket(BUCKET_NAME)\n",
    "if objects:\n",
    "    print(\"Objects in bucket:\")\n",
    "    for obj in objects:\n",
    "        print(f\" - {obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #2 - Update the object (overwrite with new content)\n",
    "\n",
    "In this exercise, you will update the content of an existing object in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = \"This is updated content.\"\n",
    "\n",
    "# the \"PUT object\" command is an upsert, so it will overwrite existing files\n",
    "response = write_text_object_to_s3(BUCKET_NAME, EXAMPLE_OBJECT_KEY, new_content)\n",
    "print(response)\n",
    "\n",
    "# Read the updated content of the object\n",
    "updated_content = read_text_object_from_s3(BUCKET_NAME, EXAMPLE_OBJECT_KEY)\n",
    "if updated_content:\n",
    "    print(f\"Content of updated object '{EXAMPLE_OBJECT_KEY}':\\n{updated_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #3 - Delete the object from the bucket\n",
    "\n",
    "In this exercise, you will delete an object from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from mypy_boto3_s3.type_defs import DeleteObjectOutputTypeDef\n",
    "except ImportError:\n",
    "    print(\"boto3-stubs[s3] not installed\")\n",
    "\n",
    "\n",
    "def delete_object_from_s3(\n",
    "    bucket_name: str,\n",
    "    object_key: str,\n",
    ") -> Optional[\"DeleteObjectOutputTypeDef\"]:\n",
    "    \"\"\"\n",
    "    Delete an object from an S3 bucket.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to delete the object from\n",
    "    :param object_key: Key of the object to delete\n",
    "    :return: Response from the delete_object call\n",
    "    \"\"\"\n",
    "    response = s3_client.delete_object(Bucket=bucket_name, Key=object_key)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Delete the example object\n",
    "response = delete_object_from_s3(bucket_name=BUCKET_NAME, object_key=EXAMPLE_OBJECT_KEY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #4 - Try to read a non-existent object\n",
    "\n",
    "In this exercise, you will attempt to read a non-existent object from the S3 bucket. \n",
    "\n",
    "Catch, suppress, and print the `ClientError` exception that is raised when you try to read a non-existent object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Trying to read the deleted object at 's3://{BUCKET_NAME}/{EXAMPLE_OBJECT_KEY}' ...\")\n",
    "\n",
    "delete_object_from_s3(bucket_name=BUCKET_NAME, object_key=EXAMPLE_OBJECT_KEY)\n",
    "\n",
    "try:\n",
    "    # try to read the deleted object\n",
    "    read_text_object_from_s3(BUCKET_NAME, EXAMPLE_OBJECT_KEY)\n",
    "except ClientError as err:\n",
    "    assert \"NoSuchKey\" in str(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #5 - Try to delete a non-existent object\n",
    "\n",
    "**Note:** the result of calling `s3_client.delete_object` on a non-existent object is not what you might expect. It succeeds whether or not there exists an object with the given key.\n",
    "\n",
    "**Note:** The HTTP status code `204` means `No Content`. Or in other words, the request is successful\n",
    "but there was nothing to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_existant_object_key = EXAMPLE_OBJECT_KEY + \"_non_existent\"\n",
    "\n",
    "# delete the non-existent object ...\n",
    "response = delete_object_from_s3(bucket_name=BUCKET_NAME, object_key=non_existant_object_key)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #6 - Error handling when deleting an object\n",
    "\n",
    "In this exercise, you will implement error handling to raise a `FileNotFoundError` if you try to delete a non-existent object, i.e., one that has already been deleted or was never written.\n",
    "\n",
    "Hint, the `s3_client.head_object(...)` method raises an error with status code `404 - File Not Found`\n",
    "if no file exists for the given object key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP_FILE_NOT_FOUND_ERROR_CODE = \"404\"\n",
    "\n",
    "\n",
    "class S3FileNotFoundError(Exception):\n",
    "    \"\"\"Raise this exception when an object at a given path is not found in S3.\"\"\"\n",
    "\n",
    "\n",
    "def delete_object_or_error_if_not_exists(bucket_name: str, object_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete an object from an S3 bucket with error handling for non-existent objects.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to delete the object from\n",
    "    :param object_key: Key of the object to delete\n",
    "\n",
    "    :raises S3FileNotFoundError: if no object exists at the given path\n",
    "    :raises ClientError: if an unexpected error occurs when using S3 that is not due to file not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the object exists\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "        # If the object exists, delete it\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=object_key)\n",
    "    except ClientError as err:\n",
    "        # If a 404 error is thrown, the object does not exist\n",
    "        err_is_due_to_file_not_found = err.response[\"Error\"][\"Code\"] == HTTP_FILE_NOT_FOUND_ERROR_CODE\n",
    "        if err_is_due_to_file_not_found:\n",
    "            raise S3FileNotFoundError(f\"The object {object_key} does not exist in bucket {bucket_name}.\")\n",
    "        else:\n",
    "            # Re-raise the exception if it's a different error\n",
    "            raise\n",
    "\n",
    "\n",
    "# Try to delete the non-existent example object with error handling\n",
    "try:\n",
    "    delete_object_or_error_if_not_exists(BUCKET_NAME, EXAMPLE_OBJECT_KEY)\n",
    "except S3FileNotFoundError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #7 - List objects in the bucket to confirm they were deleted in the previous exercises\n",
    "\n",
    "In this exercise, you will list all objects in the S3 bucket to confirm that the object has been deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects in the bucket\n",
    "objects = list_all_object_keys_in_bucket(BUCKET_NAME)\n",
    "if objects:\n",
    "    print(\"Objects in bucket:\")\n",
    "    for obj in objects:\n",
    "        print(f\" - {obj}\")\n",
    "else:\n",
    "    print(\"Bucket is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8 - List objects by prefix\n",
    "\n",
    "In this exercise, you will list objects in the S3 bucket by prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_objects_in_bucket_by_prefix(bucket_name: str, prefix: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    List objects in an S3 bucket by prefix.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to list objects from\n",
    "    :param prefix: Prefix to filter objects by\n",
    "    :return: List of object keys\n",
    "    \"\"\"\n",
    "    try:\n",
    "        objects = []\n",
    "        continuation_token = None\n",
    "        while True:\n",
    "            response: \"ListObjectsV2OutputTypeDef\" = (\n",
    "                s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, ContinuationToken=continuation_token)\n",
    "                if continuation_token\n",
    "                else s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "            )\n",
    "            objects.extend([obj[\"Key\"] for obj in response.get(\"Contents\", [])])\n",
    "            continuation_token = response.get(\"NextContinuationToken\")\n",
    "            if not continuation_token:\n",
    "                break\n",
    "        return objects\n",
    "    except ClientError as err:\n",
    "        print(f\"Failed to list objects by prefix: {err}\")\n",
    "\n",
    "\n",
    "# List objects by prefix\n",
    "prefix = \"example-a/\"\n",
    "objects_by_prefix = list_all_objects_in_bucket_by_prefix(BUCKET_NAME, prefix)\n",
    "if objects_by_prefix:\n",
    "    print(f\"Objects with prefix '{prefix}':\")\n",
    "    for obj in objects_by_prefix:\n",
    "        print(f\" - {obj}\")\n",
    "else:\n",
    "    print(f\"No objects found with prefix '{prefix}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9 - Delete a bucket, no matter what!\n",
    "\n",
    "In this exercise, you will delete the S3 bucket. Your bucket may have objects in it. Does that matter?\n",
    "\n",
    "Write a function to delete your bucket. \n",
    "\n",
    "***Be careful to point it at the right bucket using the right\n",
    "AWS credentials--or you might delete the wrong bucket!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "try:\n",
    "    from mypy_boto3_s3.type_defs import EmptyResponseMetadataTypeDef\n",
    "except ImportError:\n",
    "    print(\"boto3-stubs[s3] not installed\")\n",
    "\n",
    "\n",
    "def delete_bucket(bucket_name: str) -> Optional[\"EmptyResponseMetadataTypeDef\"]:\n",
    "    \"\"\"\n",
    "    Delete an S3 bucket, including all its objects.\n",
    "\n",
    "    If the bucket does not exist, no error is raised.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to delete\n",
    "    :return: Response from the delete_bucket call or None if there is no bucket.\n",
    "    \"\"\"\n",
    "    # First, delete all objects in the bucket\n",
    "    delete_all_objects_in_bucket(bucket_name)\n",
    "\n",
    "    # Then, delete the bucket itself\n",
    "    try:\n",
    "        response: \"EmptyResponseMetadataTypeDef\" = s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        return response\n",
    "    except ClientError as err:\n",
    "        if \"NoSuchBucket\" in str(err):\n",
    "            return\n",
    "        raise\n",
    "\n",
    "\n",
    "def delete_all_objects_in_bucket(bucket_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete all objects in an S3 bucket.\n",
    "\n",
    "    If the bucket does not exist, no error is raised.\n",
    "\n",
    "    :param bucket_name: Name of the bucket to delete objects from\n",
    "    \"\"\"\n",
    "    try:\n",
    "        object_keys = list_all_object_keys_in_bucket(bucket_name)\n",
    "    except ClientError as err:\n",
    "        if \"NoSuchBucket\" in str(err):\n",
    "            return\n",
    "        raise\n",
    "\n",
    "    for object_key in object_keys:\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "\n",
    "response = delete_bucket(BUCKET_NAME)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Bonus Exercise #1 - Recursively upload a local directory to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Generator\n",
    "\n",
    "\n",
    "def recursively_upload_dir_to_bucket(\n",
    "    local_dir_fpath: str | Path,\n",
    "    bucket_name: str,\n",
    "    target_root_prefix_in_bucket: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Recurse through a local directory and upload all files to S3 under a target prefix.\n",
    "\n",
    "    The object keys within the bucket should be the relative paths of the files within the local directory.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    path/to/local_dir/\n",
    "    ├── file1.txt\n",
    "    ├── file2.txt\n",
    "    └── subdir\n",
    "        └── file3.txt\n",
    "\n",
    "    Would be uploaded to\n",
    "\n",
    "    s3://bucket-name/target_root_prefix_in_bucket/\n",
    "    ├── file1.txt\n",
    "    ├── file2.txt\n",
    "    └── subdir/\n",
    "        └── file3.txt\n",
    "    \"\"\"\n",
    "    local_dir_fpath = Path(local_dir_fpath)\n",
    "    child_fpaths: Generator[Path, None, None] = local_dir_fpath.rglob(\"*\")\n",
    "    target_root_prefix_in_bucket = target_root_prefix_in_bucket.rstrip(\"/\")\n",
    "\n",
    "    for child_fpath in child_fpaths:\n",
    "        if child_fpath.is_file():\n",
    "            relative_fpath = child_fpath.relative_to(local_dir_fpath)\n",
    "            object_key = str(Path(target_root_prefix_in_bucket) / relative_fpath)\n",
    "            upload_file_to_bucket(child_fpath, bucket_name, object_key)\n",
    "\n",
    "\n",
    "def upload_file_to_bucket(\n",
    "    local_fpath: str | Path,\n",
    "    bucket_name: str,\n",
    "    target_key_in_bucket: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket.\n",
    "\n",
    "    :param local_fpath: Local file path to upload\n",
    "    :param bucket_name: Name of the bucket to upload the file to\n",
    "    :param target_key_in_bucket: Key to upload the file to in the bucket\n",
    "    \"\"\"\n",
    "    local_fpath = Path(local_fpath)\n",
    "    with open(local_fpath, \"rb\") as file:\n",
    "        s3_client.put_object(Bucket=bucket_name, Key=target_key_in_bucket, Body=file)\n",
    "\n",
    "\n",
    "# create a test dir locally with sample files\n",
    "test_dir = Path(\"test_dir\")\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "(test_dir / \"file1.txt\").write_text(\"This is file 1.\")\n",
    "(test_dir / \"file2.txt\").write_text(\"This is file 2.\")\n",
    "(test_dir / \"subdir\").mkdir(parents=True, exist_ok=True)\n",
    "(test_dir / \"subdir\" / \"file3.txt\").write_text(\"This is file 3.\")\n",
    "\n",
    "# clean up the bucket\n",
    "delete_bucket(BUCKET_NAME)\n",
    "create_bucket(bucket_name=BUCKET_NAME)\n",
    "\n",
    "recursively_upload_dir_to_bucket(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    local_dir_fpath=test_dir,\n",
    "    target_root_prefix_in_bucket=\"test-root-dir/\",\n",
    ")\n",
    "\n",
    "# List all objects in the bucket at the test target root\n",
    "objects = list_all_objects_in_bucket_by_prefix(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    prefix=\"test-root-dir/\",\n",
    ")\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Bonus Exercise #2 - Rename a \"folder\" in an S3 bucket\n",
    "\n",
    "S3 is a key-value store for blobs of bytes. There is no way to \"rename\" a \"folder\" in S3\n",
    "without changing the key names of each object in the \"folder\".\n",
    "\n",
    "To really feel the weight and implications of this fact, go through this exercise 🤣\n",
    "\n",
    "Ultimately, you have to copy each object one at a time, and delete the old object. For large buckets, e.g.\n",
    "data lakes with millions of files, this is a slow process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_folder_in_bucket(\n",
    "    bucket_name: str,\n",
    "    old_folder_prefix: str,\n",
    "    new_folder_prefix: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rename a \"folder\" in an S3 bucket.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Given the following structure in S3:\n",
    "\n",
    "    s3://bucket-name/<old_folder_prefix>/\n",
    "    ├── file1.txt\n",
    "    ├── file2.txt\n",
    "    └── subdir/\n",
    "        └── file3.txt\n",
    "\n",
    "    After renaming\n",
    "\n",
    "    s3://bucket-name/<new_folder_prefix>/\n",
    "    ├── file1.txt\n",
    "    ├── file2.txt\n",
    "    └── subdir/\n",
    "        └── file3.txt\n",
    "\n",
    "    :param bucket_name: Name of the S3 bucket\n",
    "    :param source_folder: Source \"folder\" path in the bucket\n",
    "    :param destination_folder: Destination \"folder\" path in the bucket\n",
    "    \"\"\"\n",
    "    old_folder_prefix = old_folder_prefix.rstrip(\"/\") + \"/\"\n",
    "    new_folder_prefix = new_folder_prefix.rstrip(\"/\") + \"/\"\n",
    "\n",
    "    # List all objects in the source folder\n",
    "    objects = list_all_objects_in_bucket_by_prefix(bucket_name=bucket_name, prefix=old_folder_prefix)\n",
    "\n",
    "    for current_key in objects:\n",
    "        new_key = current_key.replace(old_folder_prefix, new_folder_prefix, 1)\n",
    "\n",
    "        # Move the object to the new key\n",
    "        move_object_in_bucket(bucket_name=bucket_name, source_key=current_key, destination_key=new_key)\n",
    "\n",
    "\n",
    "def move_object_in_bucket(bucket_name: str, source_key: str, destination_key: str):\n",
    "    \"\"\"\n",
    "    Move an object within an S3 bucket by copying to the new key and deleting the old key.\n",
    "\n",
    "    :param bucket_name: Name of the S3 bucket\n",
    "    :param source_key: Source key of the object to move\n",
    "    :param destination_key: Destination key of the object\n",
    "    \"\"\"\n",
    "    # Copy the object to the new key\n",
    "    s3_client.copy_object(\n",
    "        Bucket=bucket_name, CopySource={\"Bucket\": bucket_name, \"Key\": source_key}, Key=destination_key\n",
    "    )\n",
    "\n",
    "    # Delete the old object\n",
    "    s3_client.delete_object(Bucket=bucket_name, Key=source_key)\n",
    "\n",
    "\n",
    "\"\"\"Test the rename_folder_in_bucket function.\"\"\"\n",
    "\n",
    "# Create test objects in the source folder\n",
    "test_source_folder = \"nested/source-folder/\"\n",
    "test_dest_folder = \"nested/destination-folder/\"\n",
    "\n",
    "create_bucket(bucket_name=BUCKET_NAME)\n",
    "\n",
    "# Upload test files to source folder\n",
    "upload_file_to_bucket(\n",
    "    local_fpath=\"test_dir/file1.txt\", bucket_name=BUCKET_NAME, target_key_in_bucket=test_source_folder + \"file1.txt\"\n",
    ")\n",
    "upload_file_to_bucket(\n",
    "    local_fpath=\"test_dir/file2.txt\", bucket_name=BUCKET_NAME, target_key_in_bucket=test_source_folder + \"file2.txt\"\n",
    ")\n",
    "upload_file_to_bucket(\n",
    "    local_fpath=\"test_dir/subdir/file3.txt\",\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    target_key_in_bucket=test_source_folder + \"subdir/file3.txt\",\n",
    ")\n",
    "\n",
    "# Rename the source folder to the destination folder\n",
    "rename_folder_in_bucket(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    old_folder_prefix=test_source_folder,\n",
    "    new_folder_prefix=test_dest_folder,\n",
    ")\n",
    "\n",
    "# List all objects in the destination folder\n",
    "objects = list_all_objects_in_bucket_by_prefix(bucket_name=BUCKET_NAME, prefix=test_dest_folder)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
